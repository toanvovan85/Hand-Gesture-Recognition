import cv2
import mediapipe as mp
import numpy as np
import time

mp_hands = mp.solutions.hands 
mp_drawing = mp.solutions.drawing_utils 
hands = mp_hands.Hands(max_num_hands = 1, min_detection_confidence = 0.7) 

cap = cv2.VideoCapture(0) 

ENA = 33
IN1 = 35
IN2 = 37

ENB = 32
IN3 = 36
IN4 = 38

GPIO.setmode(GPIO.BOARD)


GPIO.setup(ENA, GPIO.OUT, initial=GPIO.LOW)
GPIO.setup(IN1, GPIO.OUT, initial=GPIO.LOW)
GPIO.setup(IN2, GPIO.OUT, initial=GPIO.LOW)


GPIO.setup(ENB, GPIO.OUT, initial=GPIO.LOW)
GPIO.setup(IN3, GPIO.OUT, initial=GPIO.LOW)
GPIO.setup(IN4, GPIO.OUT, initial=GPIO.LOW)


def detect_gesture(hand_landmarks):
    
    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP] 
    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP] 
    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP] 
    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP] 
    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]

  
    def get_distance(point1, point2): 
        return np.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2) 


    if get_distance(thumb_tip, index_tip) < 0.05:
        return "stop"
    elif index_tip.y < thumb_tip.y and middle_tip.y < thumb_tip.y:
        return "forward"
    elif index_tip.y > thumb_tip.y and middle_tip.y > thumb_tip.y:
        return "backward" 
    elif index_tip.y < middle_tip.y and middle_tip.y < ring_tip.y and ring_tip.y < pinky_tip.y and pinky_tip.y > 0:
        return "turnleft"
    elif index_tip.y > middle_tip.y and middle_tip.y > ring_tip.y and ring_tip.y > pinky_tip.y and pinky_tip.y > 0:
        return "turnright"
    return "unknown"


def move_forward():
    GPIO.output(ENA, GPIO.HIGH)
    GPIO.output(IN1, GPIO.HIGH)
    GPIO.output(IN2, GPIO.LOW)
    GPIO.output(ENB, GPIO.HIGH)
    GPIO.output(IN3, GPIO.HIGH)
    GPIO.output(IN4, GPIO.LOW)
    print("Tien ve phia truoc")

def move_backward():
    GPIO.output(ENA, GPIO.HIGH)
    GPIO.output(IN1, GPIO.LOW)
    GPIO.output(IN2, GPIO.HIGH)
    GPIO.output(ENB, GPIO.HIGH)
    GPIO.output(IN3, GPIO.LOW)
    GPIO.output(IN4, GPIO.HIGH)
    print("Tien ve phia sau")

def stop():
    GPIO.output(ENA, GPIO.HIGH)
    GPIO.output(IN1, GPIO.LOW)
    GPIO.output(IN2, GPIO.LOW)
    GPIO.output(ENB, GPIO.HIGH)
    GPIO.output(IN3, GPIO.LOW)
    GPIO.output(IN4, GPIO.LOW)
    print("Dung lai!")

def turn_left():
    GPIO.output(ENA, GPIO.HIGH)
    GPIO.output(IN1, GPIO.LOW)
    GPIO.output(IN2, GPIO.HIGH)
    GPIO.output(ENB, GPIO.HIGH)
    GPIO.output(IN3, GPIO.HIGH)
    GPIO.output(IN4, GPIO.LOW)
    print("quay sang trai")

def turn_right():
    GPIO.output(ENA, GPIO.HIGH)
    GPIO.output(IN1, GPIO.HIGH)
    GPIO.output(IN2, GPIO.LOW)
    GPIO.output(ENB, GPIO.HIGH)
    GPIO.output(IN3, GPIO.LOW)
    GPIO.output(IN4, GPIO.HIGH)
    print("quay sang phai")

# Main loop
while cap.isOpened():
    ret, frame = cap.read() 
    if not ret:
        break
    
    frame = cv2.flip(frame, 1)
    black_image = cv2.bitwise_not(frame) 
    black_image = cv2.subtract(black_image, black_image)

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) 
    results = hands.process(frame_rgb)

    if results.multi_hand_landmarks: 
        for hand_landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(black_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            gesture = detect_gesture(hand_landmarks) 

            if gesture == "forward":
                move_forward()
            elif gesture == "backward":
                move_backward()
            elif gesture == "stop":
                stop()
            elif gesture == "turnleft":
                turn_left()
            elif gesture == "turnright":
                turn_right()

    cv2.imshow('Hand Gesture Control', black_image)
    if cv2.waitKey(1) & 0xFF == ord('q'): 
        break 


cap.release() 
cv2.destroyAllWindows() 
